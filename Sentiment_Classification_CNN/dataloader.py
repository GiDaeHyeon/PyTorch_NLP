from torch.utils.data import Dataset, DataLoaderfrom pytorch_lightning import LightningDataModulefrom konlpy.tag import Mecabfrom torchtext.legacy import datafrom torchtext.legacy.data import TabularDatasetclass NMSCtorchtextDataset(Dataset):    def __init__(self,                 max_length=None,                 train=None):        super(NMSCtorchtextDataset, self).__init__()        self.tokenizer = Mecab()        self.ID = data.Field(sequential=False,                             use_vocab=False,                             is_target=False)        self.TEXT = data.Field(sequential=True,                               use_vocab=True,                               tokenize=self.tokenizer.morphs,                               lower=False,                               batch_first=True,                               fix_length=max_length)        self.LABEL = data.Field(sequential=False,                                use_vocab=False,                                is_target=True)        train_dataset, val_dataset = TabularDataset.splits(path='/dataset',                                                           train='ratings_train.txt',                                                           test='ratings_test.txt',                                                           format='tsv',                                                           fields=[('id', self.ID),                                                                   ('text', self.TEXT),                                                                   ('label', self.LABEL)],                                                           skip_header=True)        self.vocab_size = self.TEXT.build_vocab(self.train_data, min_freq=5)        if train:            self.dataset = train_dataset        else:            self.dataset = val_dataset    def __getitem__(self, idx):        data = self.dataset[idx]        return data.text, int(data.label)    def __len__(self):        return len(self.dataset)class NMSCtorchtextDataModule(LightningDataModule):    def __init__(self,                 max_length=32,                 batch_size=128,                 num_workers=2):        self.train_dataset = NMSCtorchtextDataset(max_length=max_length,                                                  train=True)        self.val_dataset = NMSCtorchtextDataset(max_length=max_length,                                                train=False)        self.vocab_size = self.train_dataset.vocab_size        self.batch_size = batch_size        self.num_workers = num_workers    def train_dataloader(self):        return DataLoader(dataset=self.train_dataset,                          batch_size=self.batch_size,                          num_workers=self.num_workers,                          shuffle=True,                          pin_memory=True,                          persistent_workers=True,                          drop_last=True)    def val_dataloader(self):        return DataLoader(dataset=self.val_dataset,                          batch_size=self.batch_size,                          num_workers=self.num_workers,                          shuffle=False,                          pin_memory=True,                          persistent_workers=True,                          drop_last=False)